{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gitpod/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import unicodedata\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"https://raw.githubusercontent.com/4GeeksAcademy/machine-learning-content/master/assets/spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Category  5572 non-null   object\n",
      " 1   Message   5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>ham</td>\n",
       "      <td>Then we wait 4 u lor... No need 2 feel bad lar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hey leave it. not a big deal:-) take care.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1591</th>\n",
       "      <td>ham</td>\n",
       "      <td>Somewhr someone is surely made 4 u. And God ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>ham</td>\n",
       "      <td>I luv u soo much u dont understand how specia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1873</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh ok i didnt know what you meant. Yep i am ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'll text now! All creepy like so he won't thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>ham</td>\n",
       "      <td>Never try alone to take the weight of a tear t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>ham</td>\n",
       "      <td>Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3717</th>\n",
       "      <td>ham</td>\n",
       "      <td>Networking technical support associate.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "1398      ham  Then we wait 4 u lor... No need 2 feel bad lar...\n",
       "383       ham         Hey leave it. not a big deal:-) take care.\n",
       "1591      ham  Somewhr someone is surely made 4 u. And God ha...\n",
       "841       ham  I luv u soo much u dont understand how specia...\n",
       "1873      ham  Oh ok i didnt know what you meant. Yep i am ba...\n",
       "1215      ham  I'll text now! All creepy like so he won't thi...\n",
       "4547      ham  Never try alone to take the weight of a tear t...\n",
       "5561      ham  Get me out of this dump heap. My mom decided t...\n",
       "1353      ham  Let Ur Heart Be Ur Compass Ur Mind Ur Map Ur S...\n",
       "3717      ham            Networking technical support associate."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw['Message'] = df_raw['Message'].str.lower() #convierto a minuscula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to           2234\n",
       "i            2217\n",
       "you          1921\n",
       "a            1433\n",
       "the          1326\n",
       "u             996\n",
       "and           968\n",
       "is            868\n",
       "in            857\n",
       "my            755\n",
       "for           704\n",
       "your          677\n",
       "of            614\n",
       "me            611\n",
       "have          568\n",
       "call          556\n",
       "on            521\n",
       "are           487\n",
       "that          470\n",
       "it            466\n",
       "2             457\n",
       "so            423\n",
       "but           422\n",
       "or            415\n",
       "not           411\n",
       "at            400\n",
       "can           386\n",
       "ur            385\n",
       "if            382\n",
       "with          379\n",
       "will          379\n",
       "i'm           377\n",
       "be            376\n",
       "get           375\n",
       "do            364\n",
       "just          363\n",
       "we            346\n",
       "this          309\n",
       "when          283\n",
       "from          277\n",
       "&lt;#&gt;     276\n",
       "go            265\n",
       "up            264\n",
       "all           261\n",
       "no            258\n",
       "4             255\n",
       "how           254\n",
       "what          252\n",
       "now           247\n",
       ".             241\n",
       "like          236\n",
       "got           235\n",
       "know          230\n",
       "was           230\n",
       "free          228\n",
       "out           220\n",
       "come          220\n",
       "am            217\n",
       "its           209\n",
       "then          205\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw['Message'].str.split(expand=True).stack().value_counts()[:60] #corto el texto en pedacitos, asi lo veo por unidad para hacer el conteo\n",
    "\n",
    "#to , i, a, is, no son stop words, los tenemos q sacar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop=stopwords.words('english')\n",
    "\n",
    "def remove_stopwords(message):\n",
    "    if message is not None:\n",
    "        words = message.strip().split()\n",
    "        words_filtered = []\n",
    "        for word in words:\n",
    "            if word not in stop:\n",
    "                words_filtered.append(word)\n",
    "        result = \" \".join(words_filtered)  \n",
    "    else:\n",
    "        result=None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interin = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interin['Message']=df_interin['Message'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u            996\n",
       "call         556\n",
       "2            457\n",
       "ur           385\n",
       "i'm          377\n",
       "get          375\n",
       "&lt;#&gt;    276\n",
       "go           265\n",
       "4            255\n",
       ".            241\n",
       "like         236\n",
       "got          235\n",
       "know         230\n",
       "free         228\n",
       "come         220\n",
       "good         201\n",
       "?            187\n",
       "send         187\n",
       "want         183\n",
       "text         175\n",
       "time         169\n",
       "i'll         168\n",
       "...          163\n",
       "love         163\n",
       "going        161\n",
       "ok           160\n",
       "ü            157\n",
       "need         157\n",
       "r            153\n",
       "still        151\n",
       "one          150\n",
       "txt          149\n",
       "n            146\n",
       "see          145\n",
       "dont         140\n",
       "new          136\n",
       "tell         135\n",
       "think        127\n",
       "reply        126\n",
       "mobile       124\n",
       "take         124\n",
       "back         121\n",
       "stop         119\n",
       "please       118\n",
       "home         112\n",
       "day          111\n",
       "&            111\n",
       "hi           108\n",
       "claim        104\n",
       "hope         103\n",
       "make         101\n",
       "give         100\n",
       "pls           99\n",
       "me.           98\n",
       "phone         97\n",
       "now.          94\n",
       "later         94\n",
       "happy         93\n",
       "much          93\n",
       "hey           88\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interin['Message'].str.split(expand=True).stack().value_counts()[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interin['Message'] = df_interin['Message'].str.replace('.','',regex=False)\n",
    "#df_interin['Message'] = df_interin['Message'].str.replace(\"\"\"[\\?\\&\\#\\,\\]\"\"\")\n",
    "df_interin['Message']=df_interin['Message'].str.replace('''[\\?\\&\\#,;ü']''','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u         1105\n",
       "call       573\n",
       "2          472\n",
       "im         461\n",
       "ur         386\n",
       "get        382\n",
       "go         277\n",
       "ltgt       276\n",
       "ok         275\n",
       "4          269\n",
       "free       253\n",
       "know       249\n",
       "like       243\n",
       "ill        238\n",
       "got        237\n",
       "good       232\n",
       "come       228\n",
       "time       205\n",
       "want       193\n",
       "send       190\n",
       "love       189\n",
       "text       186\n",
       "day        183\n",
       "going      170\n",
       "one        170\n",
       "me         167\n",
       "need       166\n",
       "lor        160\n",
       "home       160\n",
       "you        156\n",
       "see        155\n",
       "still      154\n",
       "now        154\n",
       "sorry      153\n",
       "r          153\n",
       "stop       150\n",
       "back       150\n",
       "txt        149\n",
       "dont       147\n",
       "n          146\n",
       "reply      143\n",
       "tell       137\n",
       "new        136\n",
       "later      134\n",
       "think      132\n",
       "mobile     128\n",
       "today      128\n",
       "hi         128\n",
       "well       127\n",
       "it         127\n",
       "take       126\n",
       "please     125\n",
       "da         125\n",
       "cant       124\n",
       "phone      118\n",
       "claim      111\n",
       "night      111\n",
       "much       109\n",
       "dear       109\n",
       "hey        107\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interin['Message'].str.split(expand=True).stack().value_counts()[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_string(text_string):\n",
    "    if text_string is not None:\n",
    "        result = unicodedata.normalize('NFD',text_string).encode('ascii','ignore').decode()\n",
    "    else:\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "df_interin['Message'] = df_interin['Message'].apply(normalize_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u       1105\n",
       "call     573\n",
       "2        472\n",
       "im       470\n",
       "ur       386\n",
       "get      382\n",
       "go       277\n",
       "ltgt     276\n",
       "ok       275\n",
       "4        269\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interin['Message'].str.split(expand=True).stack().value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saca repeticion de letras tipo looooveee a love\n",
    "def replace_multiple_letters(message):\n",
    "    if message is not None:\n",
    "        result = re.sub(r'([a-zA-Z])\\1{2,}',r'\\1',message)\n",
    "    else:\n",
    "        result=None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u       1105\n",
       "call     573\n",
       "2        472\n",
       "im       470\n",
       "ur       386\n",
       "get      382\n",
       "go       277\n",
       "ltgt     276\n",
       "ok       275\n",
       "4        269\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interin['Message'] = df_interin['Message'].apply(replace_multiple_letters)\n",
    "df_interin['Message'].str.split(expand=True).stack().value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_interin.copy()\n",
    "\n",
    "X = df['Message']\n",
    "y = df['Category']\n",
    "\n",
    "#train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizo el texto de reviews a numeros \n",
    "\n",
    "vector = CountVectorizer(stop_words='english') #le saco las palabras de ingles\n",
    "X_train = vector.fit_transform(X_train).toarray() #lo convierto en matriz\n",
    "X_test = vector.transform(X_test).toarray() #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 7553)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['008704050406' '0089' '0121' ... 'zoe' 'zogtorius' 'zyada']\n"
     ]
    }
   ],
   "source": [
    "print(vector.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9930605407992342"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train, y_train) #hizo overfiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9834888729361091"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype='<U4')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vector.transform(['Hello my friend'])) # a ver q me dice si es spam o que, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype='<U4')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(vector.transform(['free for season'])) #largo spam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'calle 18dejulio nro 3254 esq pepe carloncho'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compress_date_street_name(message):\n",
    "    if message is not None:\n",
    "        expr = '(\\d{1,2})\\sde\\s([ene|feb|mar|abr|may|jun|jul|ago|set|sep|oct|nov|dic].*)'\n",
    "        result = re.sub(expr,r'\\1de\\2',message)\n",
    "    else:\n",
    "        result = None\n",
    "    return result\n",
    "\n",
    "compress_date_street_name('calle 18 de julio nro 3254 esq pepe carloncho')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grabo el modelo\n",
    "import pickle\n",
    "\n",
    "filename = '../models/nb_model.sav'\n",
    "pickle.dump(model, open(filename,'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
